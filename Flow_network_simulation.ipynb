{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a9b21ea",
   "metadata": {},
   "source": [
    "# Flow Network Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d97de8",
   "metadata": {},
   "source": [
    "### General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5144b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pylab\n",
    "# %run FastFlowNets.py 64 1 0\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys, os\n",
    "args = sys.argv\n",
    "sys.executable\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "from numpy import zeros as zeros\n",
    "from numpy import ones as ones\n",
    "from numpy import array as array\n",
    "from numpy import arange as arange\n",
    "from numpy import meshgrid as meshgrid\n",
    "from numpy import dot as dot\n",
    "from numpy.linalg import inv as inv\n",
    "\n",
    "# import cupy as cp\n",
    "\n",
    "import cProfile\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy.linalg as la\n",
    "import numpy.random as rand\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# My functions\n",
    "import NETfuncs, Constraints, Matrixfuncs, Statistics, Classes, Big_Class, FileFuncs, DatasetManipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e902a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for plots and data save\n",
    "\n",
    "# figure size\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# comp_path = \"C:\\\\Users\\\\SMR_Admin\\\\OneDrive - huji.ac.il\\\\PhD\\\\Network Simulation repo\\\\figs and data\\\\\"\n",
    "comp_path = \"C:\\\\Users\\\\roiee\\\\OneDrive - huji.ac.il\\\\PhD\\\\Network Simulation repo\\\\figs and data\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be399cf0",
   "metadata": {},
   "source": [
    "### Roie Larger Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a08d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User variables\n",
    "\n",
    "NGrid = 6  # lattice dimension is Ngrid X Ngrid\n",
    "# NGrid = 7  # for counter, lattice dimension is Ngrid X 1\n",
    "# NGrid = 3 # lattice dimansion is Ngrid X Ngrid\n",
    "Nin=3  # number of input nodes\n",
    "Nout=2  # number of output nodes\n",
    "\n",
    "task_type = 'dual_no_cell'\n",
    "# task_type = 'Allostery_one_pair'  # 1 pair of input and outputs\n",
    "# task_type = 'Allostery'  # 2 pairs of input and outputs\n",
    "# task_type = 'Allostery_contrastive'  # 1 input, 2 outputs, 1 ground\n",
    "# task_type = 'Regression_contrastive'  # 1 input, 2 outputs, 1 ground\n",
    "# task_type = 'Flow_clockwise'  # 2 pairs of input and outputs, test is flowing from both inputs to both outputs\n",
    "# task_type = 'XOR'  # 2 inputs and 2 outputs. difference between output nodes encodes the XOR result of the 2 inputs\n",
    "# task_type = 'Channeling_diag'  # 1st from input to diagonal output, then from output to 2 perpindicular nodes. \n",
    "#                                # test from input to output\n",
    "# task_type = 'Channeling_straight' # 1st from input to output on same column, then from output to 2 perpindicular nodes. \n",
    "#                                   # test from input to output (same as 1st)\n",
    "# task_type = 'Counter'  # 1 col of cells, task: # marbles in right arm of crosses equals # of drive cycles.\n",
    "# task_type = 'Memristor'  # 1 col of cells, task: # marbles in right arm of crosses equals # of drive cycles.\n",
    "# task_type = 'Iris'  # classify 3 irises (outputs) given 4 inputs. Training randomly picks input node values \n",
    "#                     # from predetermined dataset and output node to block\n",
    "# sub_task_type = '2in2out'\n",
    "sub_task_type = '2in1out'\n",
    "\n",
    "# flow_scheme='dual'\n",
    "\n",
    "if task_type == 'dual_no_cell':\n",
    "    flow_scheme='dual'\n",
    "    K_scheme='R_propto_deltap'\n",
    "    net_typ='FC'\n",
    "    u_thresh_noise_mag = 0.5  # add noise to u threshold above which marbles move - normal dist. noise, amplitude as in here\n",
    "elif task_type == 'Allostery_contrastive' or task_type=='Regression_contrastive':\n",
    "    # flow_scheme='taktak'\n",
    "    # flow_scheme='None'\n",
    "    flow_scheme='dual'\n",
    "    # K_scheme='marbles_p_lower_l_half'\n",
    "    # K_scheme='marbles_p_upper_l_half'\n",
    "    K_scheme='marbles_pressure'\n",
    "    u_thresh_noise_mag = 0.5  # add noise to u threshold above which marbles move - normal dist. noise, amplitude as in here\n",
    "    # net_typ='Nachi'\n",
    "    net_typ='Cells'\n",
    "else:\n",
    "    flow_scheme='None'\n",
    "    net_typ='Cells'\n",
    "    \n",
    "# row = int(np.floor(np.sqrt(NGrid))-1)  # row (and column) of input and output nodes in the NGrid X NGrid cell array\n",
    "row = 3\n",
    "\n",
    "# Assign input and output nodes a.f.o lattice size and row choice\n",
    "input_nodes_lst, ground_nodes_lst, output_nodes = Constraints.build_input_output_and_ground(task_type, sub_task_type, row, \n",
    "                                                                                            NGrid, Nin=Nin, Nout=Nout)\n",
    "\n",
    "## These are defaults\n",
    "# Periodic = False  # flag for lattice periodicity\n",
    "# net_typ = 'Cells'  # layout for NETfuncs plotNetStructure(). 'Cells' is my style of network and is default\n",
    "# u_thresh = 1  # threshold to move marbles\n",
    "\n",
    "\n",
    "# K_type = 'bidir'  # conductivity is the same regardless of flow directions\n",
    "K_type = 'flow_dep'  # conductivity depends on flow direction - if into cell then maximal, \n",
    "                     # if out and there is a marble then lower\n",
    "\n",
    "# Only for conductivity proportional to current squared scheme    \n",
    "# beta = 10**(-2)\n",
    "# beta = 0\n",
    "# print('beta is:' + str(beta))\n",
    "\n",
    "K_max = 1\n",
    "# K_min = np.array([0.0001])  # for counter\n",
    "# K_min = np.array([0.5])  # real value\n",
    "K_min = np.array([0.05])  # for Allostery_contrastive\n",
    "# K_min = np.array([0.1])  # for Regression_contrastive\n",
    "# K_min = np.array([1/(4*(NGrid-2*row)-1)])  # theoretical marginal for channeling\n",
    "# K_min = np.logspace(-2.2, -0.0001, num=8, base=10)\n",
    "\n",
    "# input_p = np.logspace(1.2, 2.2, num=50, base=10)\n",
    "# input_p = np.array([1])  # for counter\n",
    "# p_small = 0.1  # for memristor\n",
    "# p_large = 100  # for memristor\n",
    "# input_p = np.concatenate((np.linspace(p_small, p_large, 10),  np.linspace(p_large, p_small, 10)))  # for memristor\n",
    "input_p = np.array([1])  # for Allostery_contrastive\n",
    "\n",
    "# fixed_node_p = 5*(NGrid-1)/NGrid  # something in the middle\n",
    "fixed_node_p = 0\n",
    "\n",
    "noise = 0.0  # noise on initial marble configuration\n",
    "\n",
    "iterations = 160  # # iterations allowed under flow cycles / updating conductivities\n",
    "\n",
    "use_gpu = False\n",
    "solver = Classes.Solver(use_gpu)\n",
    "\n",
    "## Networkx sizes\n",
    "scale = 5\n",
    "squish = 0.01\n",
    "\n",
    "## for Iris dataset calssification \n",
    "train_frac = 0.8\n",
    "\n",
    "## for Contrastive learning\n",
    "# etta = 1  # not for dual\n",
    "# desired_p_frac = array([[0.25, 0.1],[0.1, 0.2]])  # regression 2in2out\n",
    "desired_p_frac = array([0.9, 0.1])  # regression 2in1out\n",
    "# desired_p_frac = array([[0.5, 0.05],[0.5, 0.05]])  # Midway solution\n",
    "# desired_p_frac = array([0.9, 0.1])  # Midway solution\n",
    "# mag_factor = (NGrid-2*row) * 6  # for Allostery and Regression, no 'taktak'\n",
    "# mag_factor = (NGrid-2*row) * 5\n",
    "mag_factor = 24  # for dual problem, an attempt\n",
    "\n",
    "u_thresh = 1  # p threshold for moving the marbles\n",
    "\n",
    "alpha=1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2406dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input nodes are:\n",
      "[0 1 2]\n",
      "ground nodes are:\n",
      "[5]\n",
      "\n",
      "output nodes are:\n",
      "[3 4]\n",
      "\n",
      "pressure is:\n",
      "1\n",
      "\n",
      "K min is:\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "## Prints\n",
    "\n",
    "# print('input output node pairs are:\\n' + str(input_output_pairs) +'\\n')\n",
    "print('input nodes are:\\n' + str(input_nodes_lst) + '\\nground nodes are:\\n' + str(ground_nodes_lst) +'\\n' + \n",
    "     '\\noutput nodes are:\\n' + str(output_nodes))\n",
    "\n",
    "print('\\npressure is:')\n",
    "for i in input_p:\n",
    "    print(i)\n",
    "    \n",
    "print('\\nK min is:')\n",
    "for i in K_min:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e3b003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allowed_cells = np.array([], dtype=int)\n",
    "# for i in range(NGrid):\n",
    "#     allowed_cells = np.append(allowed_cells, np.linspace(i*NGrid, (i+1)*NGrid-i-1, NGrid-i, dtype=int))\n",
    "# print(allowed_cells)\n",
    "\n",
    "\n",
    "# allowed_cells = np.array([], dtype=int)  # Specify the dtype as int\n",
    "# for i in range(NGrid):  # run over all lines\n",
    "# # at each line from the bottom, allowed cells are from first one to diagonal\n",
    "#     allowed_cells = np.append(allowed_cells, np.linspace(i * NGrid, i * NGrid + i, i + 1, dtype=int))\n",
    "# print(allowed_cells)    \n",
    "\n",
    "# for i in range(NGrid**2):\n",
    "#     if i not in allowed_cells:\n",
    "#         print(f'{i} not in allowed_cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db5a4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables class - mostly user choices\n",
    "\n",
    "Variabs = Classes.User_variables(NGrid, input_p, task_type, K_type, iterations, input_nodes_lst, ground_nodes_lst, \n",
    "                                 net_typ=net_typ, u_thresh=u_thresh, u_thresh_noise_mag=u_thresh_noise_mag, \n",
    "                                 output_nodes=output_nodes, K_max=K_max, K_min=K_min, K_scheme=K_scheme, train_frac=train_frac, \n",
    "                                 desired_p_frac=desired_p_frac, mag_factor=mag_factor, alpha=alpha, sub_task_type=sub_task_type,\n",
    "                                 flow_scheme=flow_scheme)\n",
    "\n",
    "if task_type == 'Counter':\n",
    "    Variabs.assign_fixed_node_p(fixed_node_p)  # assign 0 pressure at counter outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a99d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Big Class containing all classes in Network Simulation\n",
    "BigClass = Big_Class.Big_Class(Variabs)\n",
    "\n",
    "# CPU or GPU usage\n",
    "BigClass.assign_solver(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c06a292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Periodic False\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'User_variables' object has no attribute 'output_nodes_lst'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Structure class - build incidence matrices and 1d arrays of edges\u001b[39;00m\n\u001b[0;32m      3\u001b[0m Strctr \u001b[38;5;241m=\u001b[39m Classes\u001b[38;5;241m.\u001b[39mNet_structure()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mStrctr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_incidence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVariabs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Variabs\u001b[38;5;241m.\u001b[39mtask_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMemristor\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m Variabs\u001b[38;5;241m.\u001b[39mtask_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllostery_contrastive\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m Variabs\u001b[38;5;241m.\u001b[39mtask_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegression_contrastive\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      6\u001b[0m     Variabs\u001b[38;5;241m.\u001b[39mupdate_u_thresh(Strctr)\n",
      "File \u001b[1;32m~\\OneDrive - huji.ac.il\\PhD\\Network Simulation repo\\Network\\Classes.py:271\u001b[0m, in \u001b[0;36mNet_structure.build_incidence\u001b[1;34m(self, Variabs)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_incidence\u001b[39m(\u001b[38;5;28mself\u001b[39m, Variabs):\n\u001b[0;32m    257\u001b[0m \u001b[38;5;250m\t\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124;03m\tbuild_incidence builds the incidence matrix DM\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124;03m\t\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m\tNN         - int, # nodes in network\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m\t\"\"\"\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEI, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEJ, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEIEJ_plots, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDM, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNE, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNN \u001b[38;5;241m=\u001b[39m \u001b[43mMatrixfuncs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_incidence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVariabs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive - huji.ac.il\\PhD\\Network Simulation repo\\Network\\Matrixfuncs.py:135\u001b[0m, in \u001b[0;36mbuild_incidence\u001b[1;34m(Variabs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# if Variabs.Periodic==True:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m#     print('Periodic True')\u001b[39;00m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m#     for j in range(a):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m#         EI.append(i*a)\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m#         EJ.append(i*a + a-1) \u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFC\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 135\u001b[0m     Nground \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(Variabs\u001b[38;5;241m.\u001b[39minput_nodes_lst) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mVariabs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_nodes_lst\u001b[49m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    136\u001b[0m     EI \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    137\u001b[0m     EJ \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'User_variables' object has no attribute 'output_nodes_lst'"
     ]
    }
   ],
   "source": [
    "## Structure class - build incidence matrices and 1d arrays of edges\n",
    "\n",
    "Strctr = Classes.Net_structure()\n",
    "Strctr.build_incidence(Variabs)\n",
    "if Variabs.task_type == 'Memristor' or Variabs.task_type == 'Allostery_contrastive' or Variabs.task_type == 'Regression_contrastive':\n",
    "    Variabs.update_u_thresh(Strctr)\n",
    "BigClass.add_Strctr(Strctr)  # add to big class\n",
    "# Identify edges at connections of cells and at boundaries for ease of use\n",
    "Strctr.Boundaries_and_connections(BigClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05374f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initiate internal flow network state class\n",
    "\n",
    "State = Classes.Net_state(use_gpu)\n",
    "BigClass.add_State(State)  # add to big class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc80e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build network graphics class and plot structure\n",
    "\n",
    "NET = Classes.Networkx_net(scale, squish)\n",
    "NET.buildNetwork(BigClass)\n",
    "NET.build_pos_lattice(BigClass, plot='yes')\n",
    "# pos_lattice = NETfuncs.plotNetStructure(NET.NET, plot='yes', node_labels=False)  # position lattice, datatype of networkx\n",
    "# position lat. dtype=networkx\n",
    "# pos_lattice = NETfuncs.plotNetStructure(NET.NET, layout='oneCol', plot='no', node_labels=True)\n",
    "# print(NET.pos_lattice)\n",
    "BigClass.add_NET(NET)  # add to big class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f62dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_iterate_for_profiler():\n",
    "    # State.flow_iterate(BigClass, sim_type='w marbles', plot='yes', savefig='no') \n",
    "    State.flow_iterate(BigClass, sim_type='w marbles', plot='yes', savefig='no') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd545a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_thresh=np.linspace(1, 15, BigClass.Strctr.NE)\n",
    "# u_rand = (1+noise) * u_thresh * 2 * (rand.random([BigClass.Strctr.NE])-1/2)  # fictional velocity field just to move marble randomly\n",
    "# print(np.where(u_rand > rand.random([BigClass.Strctr.NE])))\n",
    "# print(type(u_thresh)==np.ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a5f0e6",
   "metadata": {},
   "source": [
    "### Main part - loop over both cond and pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742a66a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# flow MSE and conductivity Hamming a.f.o input pressure\n",
    "\n",
    "# Initiate MSE and Hamming matrices - MSE and Hamming for every iteration step (cols) a.f.o input p (rows)\n",
    "MSE_arr = np.zeros([Variabs.iterations, len(K_min), len(input_p)])\n",
    "Hamming_arr = np.zeros([Variabs.iterations, len(K_min), len(input_p)])\n",
    "power_dissip_arr = np.zeros([Variabs.iterations, len(K_min), len(input_p)])\n",
    "convergence_time_vec = np.zeros([len(K_min), len(input_p) ])\n",
    "shear_vec = np.zeros([len(K_min), len(input_p)])  # \n",
    "u_allostery_arr = np.zeros([2, 2, len(K_min), len(input_p)])  # \n",
    "\n",
    "print('started main loop')\n",
    "for i, K_min_i in enumerate(K_min):\n",
    "    \n",
    "    # K min into Variabs Class \n",
    "    Variabs.assign_K_min(K_min_i)\n",
    "    \n",
    "    for j, p in enumerate(input_p):\n",
    "        \n",
    "        print('p=', p)\n",
    "        \n",
    "        start = time.time()  # time start of calculation for profiling\n",
    "\n",
    "        # input pressure into Variabs Class\n",
    "        Variabs.assign_input_p(p)\n",
    "\n",
    "        # Set up constraints for whole loop\n",
    "        Strctr.Setup_constraints(BigClass)\n",
    "        \n",
    "#         print(Strctr.GroundNodes_full)\n",
    "#         print(Strctr.EdgesTotal)\n",
    "#         print(Strctr.Edges_full)\n",
    "\n",
    "        # Initiate K matrix again, not mandatory, better not doing it actually\n",
    "        State.initiateK(BigClass, noise='no', noise_amp=noise)\n",
    "        \n",
    "\n",
    "        # Loop - Pose constraints, build constraints matrix, solve flow and update conductivities until convergence,\n",
    "        #        change constraints and repeat\n",
    "        flow_iterate_for_profiler()\n",
    "        # State.flow_iterate(BigClass, sim_type='w marbles', plot='yes', savefig='no')\n",
    "        # State.flow_iterate(Variabs, Strctr, NET, sim_type='w marbles', plot='yes', savefig='yes')\n",
    "        \n",
    "        # print(State.K)\n",
    "\n",
    "        MSE_arr[:, i, j] = State.MSE\n",
    "        Hamming_arr[:, i, j] = State.Hamming\n",
    "        # print(State.power_dissip)\n",
    "        power_dissip_arr[:, i, j] = State.power_dissip\n",
    "        convergence_time_vec[i, j] = State.convergence_time\n",
    "        \n",
    "#         State.flow_iterate(BigClass, sim_type='allostery test', plot='yes', savefig='no')  # flow from both inputs\n",
    "#                                                                                            # to both outputs\n",
    "        \n",
    "#         p_mat = Statistics.p_mat(State.p, BigClass.Variabs.NGrid)\n",
    "        \n",
    "        # FileFuncs.save_csv_files_Net(BigClass, p, K_min_i, comp_path)\n",
    "      \n",
    "        u_allostery_arr[:,:, i, j] = State.u_final\n",
    "        print('p=', p)\n",
    "        # print('u=', State.u_final)\n",
    "#         shear_vec[i, j] = Statistics.shear_type(State.u_final)\n",
    "#         print('shear is: ' + str(shear_vec[i]))\n",
    "\n",
    "        end = time.time()  # time end of calculation for profiling\n",
    "        dt = end-start  # total time it took to run calculation\n",
    "        print('total time for simulation %f' %dt)\n",
    "    \n",
    "    print(str((i+1)*100/len(K_min)) + '% done')\n",
    "        \n",
    "convergence_time_vec[np.isnan(convergence_time_vec)] = Variabs.iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4dcf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('outputs_dual_vec', State.outputs_dual_vec)\n",
    "print('outputs_dual', State.outputs_dual)\n",
    "print('p_dual_vec', State.p_dual_vec)\n",
    "print('p_nudge', State.p_nudge)\n",
    "print('outputs_vec', State.outputs_vec)\n",
    "print('p_outputs', State.p_outputs)\n",
    "if task_type=='Regression_contrastive':\n",
    "    print('p_desired', Variabs.train_target[0])\n",
    "print('mag_factor', Variabs.mag_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a59276",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('error ', State.error_vec, 'error improvement ', (State.error_vec[0]-State.error_vec[1])/State.error_vec[0]*100, '%')\n",
    "plt.plot(np.abs(State.error_vec))\n",
    "if BigClass.Variabs.task_type=='Allostery_contrastive':\n",
    "    plt.plot(np.sum(np.abs(State.error_vec), 1))\n",
    "elif BigClass.Variabs.task_type=='Regression_contrastive':\n",
    "    pass\n",
    "plt.xlabel('iteration #')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da18e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(State.ratio_vec)\n",
    "# plt.plot(desired_p_frac[0,1]/desired_p_frac[0,0]*np.ones(len(State.ratio_vec)))\n",
    "# plt.ylim([-1,1.02])\n",
    "plt.xlabel('iteration #')\n",
    "plt.ylabel('ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52598150",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moving averaged ratio vec\n",
    "\n",
    "# Program to calculate moving average\n",
    "window_size = 6\n",
    " \n",
    "i = 0\n",
    "# Initialize an empty list to store moving averages\n",
    "moving_averages = []\n",
    " \n",
    "# Loop through the array to consider\n",
    "# every window of size 3\n",
    "while i < len(State.ratio_vec) - window_size + 1:\n",
    "   \n",
    "    # Store elements from i to i+window_size\n",
    "    # in list to get the current window\n",
    "    window = State.ratio_vec[i : i + window_size]\n",
    " \n",
    "    # Calculate the average of current window\n",
    "    window_average = round(sum(window) / window_size, 2)\n",
    "     \n",
    "    # Store the average of current\n",
    "    # window in moving average list\n",
    "    moving_averages.append(window_average)\n",
    "     \n",
    "    # Shift window to right by one position\n",
    "    i += 1\n",
    "    \n",
    "plt.plot(moving_averages)\n",
    "plt.title(f'moving averaged ratio window={window_size}')\n",
    "plt.ylim([0,1.3])\n",
    "plt.xlabel('sample number')\n",
    "plt.ylabel('ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523bc79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.abs(State.u_final_vec))\n",
    "# plt.plot(desired_p_frac[0,1]/desired_p_frac[0,0]*np.ones(len(State.ratio_vec)))\n",
    "# plt.ylim([0,1.02])\n",
    "plt.xlabel('iteration #')\n",
    "plt.ylabel('flow at output')\n",
    "plt.legend(['top right', 'bottom left'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab24b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save inportant data as CSV\n",
    "\n",
    "# # import pandas as pd \n",
    "\n",
    "# datenow = datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "# print(datenow)\n",
    "\n",
    "# # df1 = pd.DataFrame(u_allostery_arr)\n",
    "# # print('C:\\\\Users\\\\SMR_Admin\\\\OneDrive - huji.ac.il\\\\PhD\\\\Network Simulation repo\\\\Network\\\\u_allostery' + str(datenow) + '.csv')\n",
    "# # df1.to_csv(\"C:\\\\Users\\\\SMR_Admin\\\\OneDrive - huji.ac.il\\\\PhD\\\\Network Simulation repo\\\\Network\\\\u_allostery\" + str(datenow) + \".csv\")\n",
    "# # df2 = pd.DataFrame(w_vec)\n",
    "# # df2.to_csv(comp_path + str(datenow) + \"_grid=\" + str(NGrid) + \"_w_vec.csv\")\n",
    "# df2 = pd.DataFrame(shear_vec, columns=[str(i) for i in input_p], index=[str(i) for i in K_min])\n",
    "# df2.to_csv(comp_path + str(datenow) + \"_grid=\" + str(NGrid) + \"_shear_vec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d275fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.DataFrame(w_vec, columns=[str(i) for i in input_p], index=[str(i) for i in K_min])\n",
    "# df2.to_csv(comp_path + str(datenow) + \"_grid=\" + str(NGrid) + \"_w_vec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1167b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Figures\n",
    "\n",
    "# # prelims for figures\n",
    "# datenow = datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "# print(datenow)\n",
    "\n",
    "# # fig 1 - MSE, Hamming and Power dissip. afo p\n",
    "\n",
    "# fig1, axes1 = plt.subplots(nrows=3)\n",
    "# # axes.set_color_cycle(['332288', '88CCEE', '44AA99', '117733', '999933', 'DDCC77', 'CC6677', '882255', 'AA4499'])\n",
    "# # cmap = plt.get_cmap('cool')\n",
    "# cmap = sns.cubehelix_palette(as_cmap=True)\n",
    "# colors = [cmap(i) for i in np.linspace(0, 1, len(MSE_arr[0,:]))]\n",
    "# legend_every = 10\n",
    "\n",
    "# for i, color in enumerate(colors, start=0):\n",
    "#     if i % legend_every == 0:\n",
    "#         axes1[0].plot(range(len(MSE_arr[:,0])), MSE_arr[:,i], color=color, label='K ratio='+str(K_min[i]))\n",
    "#     else:\n",
    "#         axes1[0].plot(range(len(MSE_arr[:,0])), MSE_arr[:,i], color=color)\n",
    "#     axes1[1].plot(range(len(MSE_arr[:,0])), Hamming_arr[:,i], color=color)\n",
    "#     axes1[2].plot(range(len(MSE_arr[:,0])), power_dissip_arr[:,i]/input_p[0], color=color)\n",
    "# axes1[0].legend()\n",
    "# # plt.show()\n",
    "# axes1[2].set_xlabel('iteration #')\n",
    "# axes1[0].set_ylabel('flow MSE')\n",
    "# axes1[1].set_ylabel('Hamming dist.')\n",
    "# axes1[2].set_ylabel('power')\n",
    "\n",
    "# ## Save last figure as PNG with proper time\n",
    "# plt.savefig(comp_path + 'distance_and_P_afo_Kratio_' + \"_grid=\" + str(NGrid) + \"_\" + str(datenow) + '.png')\n",
    "\n",
    "# # fig 2 - # cycles until convergence and tau p\n",
    "\n",
    "# fig2, axes2 = plt.subplots(nrows=2, figsize=(10,6))\n",
    "# axes2[0].semilogx(K_min, convergence_time_vec, '.', ms=20, mfc='white', label='# cycles until convergence')\n",
    "# axes2[0].set_ylabel('# cycles')\n",
    "# # axes2[1].plot(input_p, theta_vec, '.', ms=20, mfc='white', label='$\\\\theta$')\n",
    "# # axes2[1].set_xlabel('input $p$')\n",
    "# # axes2[1].set_ylabel('$\\\\theta$')\n",
    "# axes2[1].semilogx(K_min, shear_vec, '.', ms=20, mfc='white', label='$\\\\tau$')\n",
    "# axes2[1].semilogx(K_min, np.zeros([len(K_min),]))\n",
    "# axes2[1].set_xlabel('$\\\\frac{K_{min}}{K_{max}}$')\n",
    "# axes2[1].set_ylabel('$\\\\tau$')\n",
    "\n",
    "# ## Save last figure as PNG with proper time\n",
    "# plt.savefig(comp_path + 'numCycles_and_tau_afo_Kratio_' + \"_grid=\" + str(NGrid) + \"_\" + str(datenow) + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
