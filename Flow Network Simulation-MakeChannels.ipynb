{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a9b21ea",
   "metadata": {},
   "source": [
    "# Flow Network Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d97de8",
   "metadata": {},
   "source": [
    "### General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5144b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pylab\n",
    "# %run FastFlowNets.py 64 1 0\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys, os\n",
    "args = sys.argv\n",
    "sys.executable\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "from numpy import zeros as zeros\n",
    "from numpy import ones as ones\n",
    "from numpy import array as array\n",
    "from numpy import arange as arange\n",
    "from numpy import meshgrid as meshgrid\n",
    "from numpy import dot as dot\n",
    "from numpy.linalg import inv as inv\n",
    "\n",
    "import cProfile\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy.linalg as la\n",
    "import numpy.random as rand\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "\n",
    "# My functions\n",
    "import NETfuncs, Constraints, Matrixfuncs, Solve, Statistics, Classes, Big_Class, FileFuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for plots and data save\n",
    "\n",
    "# figure size\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# comp_path = \"C:\\\\Users\\\\SMR_Admin\\\\OneDrive - huji.ac.il\\\\PhD\\\\Network Simulation repo\\\\figs and data\\\\\"\n",
    "comp_path = \"C:\\\\Users\\\\roiee\\\\OneDrive - huji.ac.il\\\\PhD\\\\Network Simulation repo\\\\figs and data\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be399cf0",
   "metadata": {},
   "source": [
    "### Roie Larger Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User variables\n",
    "\n",
    "NGrid = 12  # lattice dimension is Ngrid X Ngrid\n",
    "# NGrid = 3  # lattice dimansion is Ngrid X Ngrid\n",
    "\n",
    "# task_type = 'Allostery_one_pair'  # 1 pair of input and outputs\n",
    "task_type = 'Allostery'  # 2 pairs of input and outputs\n",
    "# task_type = 'Flow_clockwise'  # 2 pairs of input and outputs, test is flowing from both inputs to both outputs\n",
    "# task_type = 'XOR'  # 2 inputs and 2 outputs. difference between output nodes encodes the XOR result of the 2 inputs\n",
    "# task_type = 'Channeling_diag'  # 1st from input to diagonal output, then from output to 2 perpindicular nodes. \n",
    "#                                # test from input to output\n",
    "# task_type = 'Channeling_straight' # 1st from input to output on same column, then from output to 2 perpindicular nodes. \n",
    "#                                   # test from input to output (same as 1st)\n",
    "    \n",
    "# row = int(np.floor(np.sqrt(NGrid))-1)  # row (and column) of input and output nodes in the NGrid X NGrid cell array\n",
    "row = 0\n",
    "\n",
    "# Assign input and output nodes a.f.o lattice size and row choice\n",
    "input_output_pairs, fixed_node_pairs = Constraints.build_input_output_and_fixed(task_type, row, NGrid)\n",
    "\n",
    "## These are defaults\n",
    "# Periodic = False  # flag for lattice periodicity\n",
    "# net_typ = 'Cells'  # layout for NETfuncs plotNetStructure(). 'Cells' is my style of network and is default\n",
    "# u_thresh = 1  # threshold to move marbles\n",
    "\n",
    "# Schemes to change conductivities and order of pressure appliance in training and test\n",
    "if task_type == 'Allostery_one_pair':\n",
    "    K_scheme = 'propto_current_squared'\n",
    "    flow_scheme = 'one_shot'  # apply pressure drop from 1 output node and 1 output node, wait till convergence\n",
    "elif task_type == 'Channeling_straight' or task_type == 'Channeling_diag':\n",
    "    K_scheme = 'marbles_pressure'\n",
    "    flow_scheme = 'one_shot'  # apply pressure drop from 1 output node and 1 output node, wait till convergence\n",
    "else:\n",
    "    K_scheme = 'marbles_pressure'\n",
    "    flow_scheme = 'unidir'  # apply pressure drop only in the regular directions - constrained node = positive, ground = 0\n",
    "                            # there are 2 input and output pairs, exchange between them\n",
    "    # flow_scheme = 'taktak'  # apply pressure drop unidir once, meaning 1st input and output pair and then 2nd pair.\n",
    "                              # then switch ground and constrained nodes to apply oposite dir.\n",
    "\n",
    "# K_type = 'bidir'  # conductivity is the same regardless of flow directions\n",
    "K_type = 'flow_dep'  # conductivity depends on flow direction - if into cell then maximal, \n",
    "                     # if out and there is a marble then lower\n",
    "\n",
    "# Only for conductivity proportional to current squared scheme    \n",
    "beta = 10**(-2)\n",
    "# beta = 0\n",
    "# print('beta is:' + str(beta))\n",
    "\n",
    "K_max = 1\n",
    "# K_min = np.array([0.3])\n",
    "# K_min = np.array([1/(4*(NGrid-2*row)-1)])  # theoretical marginal for channeling\n",
    "K_min = np.logspace(-4, 0, num=6, base=10)\n",
    "\n",
    "input_p = np.logspace(1, 5, num=6, base=10)\n",
    "# input_p = np.array([10])\n",
    "\n",
    "iterations = 16  # # iterations allowed under flow cycles / updating conductivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2406dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prints\n",
    "\n",
    "print('input output node pairs are:\\n' + str(input_output_pairs) +'\\n')\n",
    "\n",
    "print('pressure is:')\n",
    "for i in input_p:\n",
    "    print(i)\n",
    "    \n",
    "print('\\n K min is:')\n",
    "for i in K_min:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables class - mostly user choices\n",
    "\n",
    "Variabs = Classes.User_variables(NGrid, input_p, flow_scheme, task_type, K_scheme, K_type, iterations, input_output_pairs, \n",
    "                                 Periodic='False', net_typ='Cells', u_thresh=1, fixed_node_pairs=fixed_node_pairs, \n",
    "                                 K_max=K_max, K_min=K_min, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a99d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Big Class containing all classes in Network Simulation\n",
    "\n",
    "BigClass = Big_Class.Big_Class(Variabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c06a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Structure class - build incidence matrices and 1d arrays of edges\n",
    "\n",
    "Strctr = Classes.Net_structure()\n",
    "Strctr.build_incidence(Variabs)\n",
    "BigClass.add_Strctr(Strctr)  # add to big class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05374f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initiate internal flow network state class\n",
    "\n",
    "State = Classes.Net_state()\n",
    "BigClass.add_State(State)  # add to big class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc80e7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## build network graphics class and plot structure\n",
    "\n",
    "NET = Classes.Networkx_net()\n",
    "NET.buildNetwork(BigClass)\n",
    "NET.build_pos_lattice(BigClass)\n",
    "pos_lattice = NETfuncs.plotNetStructure(NET.NET, plot='yes', node_labels=False)  # position lattice, datatype of networkx\n",
    "BigClass.add_NET(NET)  # add to big class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a5f0e6",
   "metadata": {},
   "source": [
    "### Main part - loop over both cond and pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742a66a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# flow MSE and conductivity Hamming a.f.o input pressure\n",
    "\n",
    "# Initiate MSE and Hamming matrices - MSE and Hamming for every iteration step (cols) a.f.o input p (rows)\n",
    "MSE_arr = np.zeros([Variabs.iterations, len(K_min), len(input_p)])\n",
    "Hamming_arr = np.zeros([Variabs.iterations, len(K_min), len(input_p)])\n",
    "power_dissip_arr = np.zeros([Variabs.iterations, len(K_min), len(input_p)])\n",
    "convergence_time_vec = np.zeros([len(K_min), len(input_p) ])\n",
    "w_vec = np.zeros([len(K_min), len(input_p)])  # circulation\n",
    "diagon_arr = np.zeros([len(K_min), len(input_p)])  # diagonality\n",
    "u_allostery_arr = np.zeros([2, 2, len(K_min), len(input_p)])  # \n",
    "\n",
    "# Identify edges at connections of cells and at boundaries for ease of use\n",
    "Strctr.Boundaries_and_connections(BigClass)\n",
    "\n",
    "print('started main loop')\n",
    "for i, K_min_i in enumerate(K_min):\n",
    "    \n",
    "    # K min into Variabs Class \n",
    "    Variabs.assign_K_min(K_min_i)\n",
    "    \n",
    "    for j, p in enumerate(input_p):\n",
    "        \n",
    "        start = time.time()  # time start of calculation for profiling\n",
    "\n",
    "        # input pressure into Variabs Class\n",
    "        Variabs.assign_input_p(p)\n",
    "\n",
    "        # Set up constraints for whole loop\n",
    "        Strctr.Setup_constraints(BigClass)\n",
    "\n",
    "        # Initiate K matrix again, not mandatory, better not doing it actually\n",
    "        State.initiateK(BigClass, noise='rand_u', noise_amp=0.5)\n",
    "        # print(State.K)\n",
    "\n",
    "        # Loop - Pose constraints, build constraints matrix, solve flow and update conductivities until convergence,\n",
    "        #        change constraints and repeat\n",
    "        State.flow_iterate(BigClass, sim_type='w marbles', plot='no', savefig='no')\n",
    "        # State.flow_iterate(Variabs, Strctr, NET, sim_type='w marbles', plot='yes', savefig='yes')\n",
    "        \n",
    "        # print(State.K)\n",
    "\n",
    "        MSE_arr[:, i, j] = State.MSE\n",
    "        Hamming_arr[:, i, j] = State.Hamming\n",
    "        # print(State.power_dissip)\n",
    "        power_dissip_arr[:, i, j] = State.power_dissip\n",
    "        convergence_time_vec[i, j] = State.convergence_time\n",
    "        \n",
    "        State.flow_iterate(BigClass, sim_type='allostery test', plot='yes', savefig='no')  # flow from both inputs\n",
    "                                                                                           # to both outputs\n",
    "        \n",
    "        p_mat = Statistics.p_mat(State.p, BigClass.Variabs.NGrid)\n",
    "#         R_typ = (1/1 + 1/1) * (NGrid-(2*row)) + 2\n",
    "#         u_typ = input_p[0]/R_typ\n",
    "        w_ij = Statistics.curl_direction(State.u, BigClass.Variabs.NGrid)  # calculate curl/vorticity\n",
    "        \n",
    "        a = State.u_final[0,0]\n",
    "        b = State.u_final[0,1]\n",
    "        c = State.u_final[1,0]\n",
    "        d = State.u_final[1,1]\n",
    "        diagon_ij = (a**2 + d**2)/(b**2 + c**2)\n",
    "        print('diagonality %f' % diagon_ij)\n",
    "        diagon_arr[i, j] = diagon_ij\n",
    "        \n",
    "        # w_vec[i, j] = w_ij/u_typ\n",
    "        w_vec[i, j] = w_ij\n",
    "        print('w_ij_norm %f' % w_vec[i, j])\n",
    "        \n",
    "        # FileFuncs.save_csv_files_Net(BigClass, p, K_min_i, comp_path)\n",
    "      \n",
    "#         datenow = datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "#         df_p = pd.DataFrame(np.array(State.p))\n",
    "#         df_p.to_csv(comp_path + str(datenow) + \"_grid=\" + str(NGrid) + \"_p=\" + str(p) + \"_K_ratio=\" \n",
    "#                     + str(K_min_i) + \"_p_field.csv\")\n",
    "#         df_u = pd.DataFrame(np.array(State.u_all[:,-1]))\n",
    "#         df_u.to_csv(comp_path + str(datenow) + \"_grid=\" + str(NGrid) + \"_p=\" + str(p) + \"_K_ratio=\" \n",
    "#                     + str(K_min_i) + \"_u_field.csv\")\n",
    "#         df_K = pd.DataFrame(np.array(State.K))\n",
    "#         df_K.to_csv(comp_path + str(datenow) + \"_grid=\" + str(NGrid) + \"_p=\" + str(p) + \"_K_ratio=\" \n",
    "#                     + str(K_min_i) + \"_K.csv\")\n",
    "\n",
    "        end = time.time()  # time end of calculation for profiling\n",
    "        dt = end-start  # total time it took to run calculation\n",
    "        print('total time for simulation %f' %dt)\n",
    "        \n",
    "convergence_time_vec[np.isnan(convergence_time_vec)] = Variabs.iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mat = Statistics.p_mat(State.p, BigClass.Variabs.NGrid)\n",
    "# fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# Make data.\n",
    "X = np.arange(np.shape(p_mat)[0])\n",
    "Y = np.arange(np.shape(p_mat)[1])\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "# Plot the surface.\n",
    "plt.contourf(X, Y, p_mat, cmap=plt.cm.coolwarm,\n",
    "         linewidth=0, antialiased=False)\n",
    "\n",
    "print(p_mat)\n",
    "print(p_mat[NGrid-row,NGrid-row])\n",
    "print(p_mat[NGrid-row,row])\n",
    "print(p_mat[row,NGrid-row])\n",
    "print(p_mat[row,row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c31f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w_vec\n",
    "K_min_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf15e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save inportant data as CSV\n",
    "\n",
    "# import pandas as pd \n",
    "\n",
    "datenow = datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "print(datenow)\n",
    "\n",
    "# df1 = pd.DataFrame(u_allostery_arr)\n",
    "# print('C:\\\\Users\\\\SMR_Admin\\\\OneDrive - huji.ac.il\\\\PhD\\\\Network Simulation repo\\\\Network\\\\u_allostery' + str(datenow) + '.csv')\n",
    "# df1.to_csv(\"C:\\\\Users\\\\SMR_Admin\\\\OneDrive - huji.ac.il\\\\PhD\\\\Network Simulation repo\\\\Network\\\\u_allostery\" + str(datenow) + \".csv\")\n",
    "# df2 = pd.DataFrame(w_vec)\n",
    "# df2.to_csv(comp_path + str(datenow) + \"_grid=\" + str(NGrid) + \"_w_vec.csv\")\n",
    "df2 = pd.DataFrame(w_vec, columns=[str(i) for i in input_p], index=[str(i) for i in K_min])\n",
    "df2.to_csv(comp_path + str(datenow) + \"_grid=\" + str(NGrid) + \"_w_vec.csv\")\n",
    "df2 = pd.DataFrame(diagon_arr, columns=[str(i) for i in input_p], index=[str(i) for i in K_min])\n",
    "df2.to_csv(comp_path + str(datenow) + \"_grid=\" + str(NGrid) + \"_diagon_arr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df358c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(w_vec, columns=[str(i) for i in input_p], index=[str(i) for i in K_min])\n",
    "df2.to_csv(comp_path + str(datenow) + \"_grid=\" + str(NGrid) + \"_w_vec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1167b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figures\n",
    "\n",
    "# prelims for figures\n",
    "datenow = datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "print(datenow)\n",
    "\n",
    "# fig 1 - MSE, Hamming and Power dissip. afo p\n",
    "\n",
    "fig1, axes1 = plt.subplots(nrows=3)\n",
    "# axes.set_color_cycle(['332288', '88CCEE', '44AA99', '117733', '999933', 'DDCC77', 'CC6677', '882255', 'AA4499'])\n",
    "# cmap = plt.get_cmap('cool')\n",
    "cmap = sns.cubehelix_palette(as_cmap=True)\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, len(MSE_arr[0,:]))]\n",
    "legend_every = 10\n",
    "\n",
    "for i, color in enumerate(colors, start=0):\n",
    "    if i % legend_every == 0:\n",
    "        axes1[0].plot(range(len(MSE_arr[:,0])), MSE_arr[:,i], color=color, label='K ratio='+str(K_min[i]))\n",
    "    else:\n",
    "        axes1[0].plot(range(len(MSE_arr[:,0])), MSE_arr[:,i], color=color)\n",
    "    axes1[1].plot(range(len(MSE_arr[:,0])), Hamming_arr[:,i], color=color)\n",
    "    axes1[2].plot(range(len(MSE_arr[:,0])), power_dissip_arr[:,i]/input_p[0], color=color)\n",
    "axes1[0].legend()\n",
    "# plt.show()\n",
    "axes1[2].set_xlabel('iteration #')\n",
    "axes1[0].set_ylabel('flow MSE')\n",
    "axes1[1].set_ylabel('Hamming dist.')\n",
    "axes1[2].set_ylabel('power')\n",
    "\n",
    "## Save last figure as PNG with proper time\n",
    "plt.savefig(comp_path + 'distance_and_P_afo_Kratio_' + \"_grid=\" + str(NGrid) + \"_\" + str(datenow) + '.png')\n",
    "\n",
    "# fig 2 - # cycles until convergence and tau p\n",
    "\n",
    "fig2, axes2 = plt.subplots(nrows=2, figsize=(10,6))\n",
    "axes2[0].semilogx(K_min, convergence_time_vec, '.', ms=20, mfc='white', label='# cycles until convergence')\n",
    "axes2[0].set_ylabel('# cycles')\n",
    "# axes2[1].plot(input_p, theta_vec, '.', ms=20, mfc='white', label='$\\\\theta$')\n",
    "# axes2[1].set_xlabel('input $p$')\n",
    "# axes2[1].set_ylabel('$\\\\theta$')\n",
    "axes2[1].semilogx(K_min, w_vec, '.', ms=20, mfc='white', label='$\\\\tau$')\n",
    "axes2[1].semilogx(K_min, np.zeros([len(K_min),]))\n",
    "axes2[1].set_xlabel('$\\\\frac{K_{min}}{K_{max}}$')\n",
    "axes2[1].set_ylabel('$\\\\tau$')\n",
    "\n",
    "## Save last figure as PNG with proper time\n",
    "plt.savefig(comp_path + 'numCycles_and_tau_afo_Kratio_' + \"_grid=\" + str(NGrid) + \"_\" + str(datenow) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6349bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "State.u_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a955e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(State.u))*NGrid**2\n",
    "# R_typ1 = (1/1 + 1/K_min[0])**(-1) * (NGrid-(2*row))\n",
    "R_typ2 = (1/1 + 1/1)**(-1) * (NGrid-(2*row))\n",
    "R_typ1 = R_typ2\n",
    "R_typ = (R_typ1 + R_typ2)/2\n",
    "u_typ = input_p[0]/R_typ\n",
    "print(u_typ)\n",
    "print(w_vec)\n",
    "print(w_vec/u_typ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a191a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NGrid = 12\n",
    "# u = State.u\n",
    "\n",
    "NGrid = 2\n",
    "row = 0\n",
    "delta_p = 4\n",
    "# u = np.array([1, 0, -1, 0, 2, 0, -2, 0, 3, 0, -3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "#               -3, 0, 3, 0, -2, 0, 2, 0, -1, 0, 1, 0])\n",
    "# u = np.array([0, 1, 0, -1, 0, 0, 0, 0, 0, -3, 0, 3, 0 , 2, 0, -2, 0, 0, 0, 0, 0, -2, 0, \n",
    "#               2, 0, 3, 0, -3, 0, 0, 0, 0, 0, -1, 0, 1])\n",
    "u = 1*np.array([0, 1, 0, -1, 0, -1, 0, 1, 0, 1, 0, -1, 0, -1, 0, 1])\n",
    "print(np.size(u))\n",
    "u_by_cells = np.zeros([NGrid*NGrid,2])\n",
    "for i in range(NGrid*NGrid):\n",
    "    u_by_cells[i,0] = (u[4*i]+(-u[4*i+2]))/2\n",
    "    u_by_cells[i,1] = (u[4*i+1]+(-u[4*i+3]))/2\n",
    "u_by_cells = np.reshape(u_by_cells, [NGrid, NGrid, 2])\n",
    "u_by_cells_mag = np.sqrt(u_by_cells[:,:,0]**2+u_by_cells[:,:,1]**2)\n",
    "\n",
    "print(u_by_cells[:,:,0])\n",
    "print(u_by_cells[:,:,1])\n",
    "\n",
    "print(u_by_cells_mag)\n",
    "# R_typ = (1/1 + 1/1) * (NGrid-(2*row))\n",
    "# u_typ = delta_p/R_typ\n",
    "u_typ=1\n",
    "# print('u_typ %f' % u_typ)\n",
    "\n",
    "w = Statistics.curl_direction(u, NGrid)\n",
    "w_norm = w/u_typ\n",
    "print('u %f' % np.mean(np.abs(u_by_cells_mag)))\n",
    "print('w %f' % w)\n",
    "print('w_norm %f' % w_norm)\n",
    "\n",
    "# print('u_by_cells')\n",
    "# print(u_by_cells[:,:,0])\n",
    "# print(u_by_cells[:,:,1])\n",
    "\n",
    "# dxuy = np.append(np.diff(u_by_cells[:,:,1],axis=1).T, [np.diff(u_by_cells[:,:,1],axis=1)[:,-1]], axis=0).T\n",
    "# print('dxuy')\n",
    "# print(dxuy)\n",
    "# dyux = np.append(np.diff(u_by_cells[:,:,0],axis=0), [np.diff(u_by_cells[:,:,0],axis=0)[-1,:]], axis=0)\n",
    "# print('dyux')\n",
    "# print(dyux)\n",
    "# curl = dxuy-dyux\n",
    "# u_mean = np.mean(np.mean(np.abs(u_by_cells)))\n",
    "# print('u_mean is %f' % u_mean)\n",
    "# curl_norm = curl/u_mean\n",
    "# print(curl_norm)\n",
    "# print(np.mean(np.mean(curl_norm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4bd00b",
   "metadata": {},
   "source": [
    "### Main part - loop over many conductivity ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb322f94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # flow MSE and conductivity Hamming a.f.o input pressure\n",
    "\n",
    "# # Initiate MSE and Hamming matrices - MSE and Hamming for every iteration step (cols) a.f.o input p (rows)\n",
    "# MSE_arr = np.zeros([Variabs.iterations, len(K_min)])\n",
    "# Hamming_arr = np.zeros([Variabs.iterations, len(K_min)])\n",
    "# power_dissip_arr = np.zeros([Variabs.iterations, len(K_min)])\n",
    "# convergence_time_vec = np.zeros([len(K_min), ])\n",
    "# shear_vec = np.zeros([len(K_min), ])  # \n",
    "# u_allostery_arr = np.zeros([2, 2, len(K_min)])  # \n",
    "\n",
    "# # Identify edges at connections of cells and at boundaries for ease of use\n",
    "# Strctr.Boundaries_and_connections(Variabs)\n",
    "\n",
    "# origin = np.array([[0, 0],[0, 0]]) # origin point\n",
    "\n",
    "# print('started main loop')\n",
    "\n",
    "# for i, K_min_i in enumerate(K_min):\n",
    "    \n",
    "#     # save variables into class\n",
    "#     Variabs.assign_K_min(K_min_i)\n",
    "    \n",
    "#     # Set up constraints for whole loop\n",
    "#     Strctr.Setup_constraints(Variabs)\n",
    "    \n",
    "#     # Initiate K matrix again, not mandatory, better not doing it actually\n",
    "#     State.initiateK(Variabs, Strctr, noise='yes')\n",
    "#     print(State.K)\n",
    "    \n",
    "#     # Loop - Pose constraints, build constraints matrix, solve flow and update conductivities until convergence,\n",
    "#     #        change constraints and repeat\n",
    "#     State.flow_iterate(Variabs, Strctr, NET, 'w marbles', 'no')\n",
    "    \n",
    "#     MSE_arr[:, i] = State.MSE\n",
    "#     Hamming_arr[:, i] = State.Hamming\n",
    "#     # print(State.power_dissip)\n",
    "#     power_dissip_arr[:, i] = State.power_dissip\n",
    "#     convergence_time_vec[i] = State.convergence_time\n",
    "    \n",
    "#     State.flow_iterate(Variabs, Strctr, NET, 'allostery test', 'yes')\n",
    "#     print(State.u_final)\n",
    "    \n",
    "# #     Variabs.iterations = 1\n",
    "# #     State.flow_iterate(Variabs, Strctr, NET, 'w marbles', 'yes')\n",
    "# #     State.flow_iterate(Variabs, Strctr, NET, 'allostery test', 'yes')\n",
    "# #     print(State.u_final)\n",
    "    \n",
    "# #     Variabs.iterations = 2\n",
    "# #     State.flow_iterate(Variabs, Strctr, NET, 'w marbles', 'yes')\n",
    "# #     State.flow_iterate(Variabs, Strctr, NET, 'allostery test', 'yes')\n",
    "# #     print(State.u_final)\n",
    "    \n",
    "# #     Variabs.iterations = 3\n",
    "# #     State.flow_iterate(Variabs, Strctr, NET, 'w marbles', 'no')\n",
    "# #     State.flow_iterate(Variabs, Strctr, NET, 'allostery test', 'last')\n",
    "# #     print(State.u_final)\n",
    "    \n",
    "# #     Variabs.iterations = iterations\n",
    "    \n",
    "#     u_allostery_arr[:,:, i] = State.u_final\n",
    "#     shear_vec[i] = Statistics.shear_type(State.u_final)\n",
    "#     print('shear is: ' + str(shear_vec[i]))\n",
    "    \n",
    "#     print(str((i+1)*100/len(K_min)) + '% done')\n",
    "\n",
    "# convergence_time_vec[np.isnan(convergence_time_vec)] = Variabs.iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.mean(State.p))\n",
    "# np.max(State.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e434e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Figures\n",
    "\n",
    "# # prelims for figures\n",
    "# datenow = datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "# print(datenow)\n",
    "\n",
    "# # fig 1 - MSE, Hamming and Power dissip. afo p\n",
    "\n",
    "# fig1, axes1 = plt.subplots(nrows=3)\n",
    "# # axes.set_color_cycle(['332288', '88CCEE', '44AA99', '117733', '999933', 'DDCC77', 'CC6677', '882255', 'AA4499'])\n",
    "# # cmap = plt.get_cmap('cool')\n",
    "# cmap = sns.cubehelix_palette(as_cmap=True)\n",
    "# colors = [cmap(i) for i in np.linspace(0, 1, len(MSE_arr[0,:]))]\n",
    "# legend_every = 10\n",
    "\n",
    "# for i, color in enumerate(colors, start=0):\n",
    "#     if i % legend_every == 0:\n",
    "#         axes1[0].plot(range(len(MSE_arr[:,0])), MSE_arr[:,i], color=color, label='K ratio='+str(K_min[i]))\n",
    "#     else:\n",
    "#         axes1[0].plot(range(len(MSE_arr[:,0])), MSE_arr[:,i], color=color)\n",
    "#     axes1[1].plot(range(len(MSE_arr[:,0])), Hamming_arr[:,i], color=color)\n",
    "#     axes1[2].plot(range(len(MSE_arr[:,0])), power_dissip_arr[:,i]/input_p[0], color=color)\n",
    "# axes1[0].legend()\n",
    "# # plt.show()\n",
    "# axes1[2].set_xlabel('iteration #')\n",
    "# axes1[0].set_ylabel('flow MSE')\n",
    "# axes1[1].set_ylabel('Hamming dist.')\n",
    "# axes1[2].set_ylabel('power')\n",
    "\n",
    "# ## Save last figure as PNG with proper time\n",
    "# plt.savefig(comp_path + 'distance_and_P_afo_Kratio_' + \"_grid=\" + str(NGrid) + \"_\" + str(datenow) + '.png')\n",
    "\n",
    "# # fig 2 - # cycles until convergence and tau p\n",
    "\n",
    "# fig2, axes2 = plt.subplots(nrows=2, figsize=(10,6))\n",
    "# axes2[0].semilogx(K_min, convergence_time_vec, '.', ms=20, mfc='white', label='# cycles until convergence')\n",
    "# axes2[0].set_ylabel('# cycles')\n",
    "# # axes2[1].plot(input_p, theta_vec, '.', ms=20, mfc='white', label='$\\\\theta$')\n",
    "# # axes2[1].set_xlabel('input $p$')\n",
    "# # axes2[1].set_ylabel('$\\\\theta$')\n",
    "# axes2[1].semilogx(K_min, shear_vec, '.', ms=20, mfc='white', label='$\\\\tau$')\n",
    "# axes2[1].semilogx(K_min, np.zeros([len(K_min),]))\n",
    "# axes2[1].set_xlabel('$\\\\frac{K_{min}}{K_{max}}$')\n",
    "# axes2[1].set_ylabel('$\\\\tau$')\n",
    "\n",
    "# ## Save last figure as PNG with proper time\n",
    "# plt.savefig(comp_path + 'numCycles_and_tau_afo_Kratio_' + \"_grid=\" + str(NGrid) + \"_\" + str(datenow) + '.png')\n",
    "\n",
    "# # fig2 = plt.figure(figsize = (10,4))\n",
    "# # plt.plot(input_p, convergence_time_vec, '.', ms=20, mfc='white', label='# cycles until convergence')\n",
    "# # plt.xlabel('input $p$')\n",
    "# # plt.ylabel('# cycles')\n",
    "# # # plt.legend(loc='upper right')\n",
    "# # plt.legend()\n",
    "\n",
    "# # plt.show()\n",
    "\n",
    "# # fig3 = plt.figure(figsize = (10,4))\n",
    "# # plt.plot(input_p, theta_vec, '.', ms=20, mfc='white', label='$\\\\theta$')\n",
    "# # plt.xlabel('input $p$')\n",
    "# # plt.ylabel('$\\\\theta$')\n",
    "# # # plt.legend(loc='upper right')\n",
    "# # plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212b4182",
   "metadata": {},
   "source": [
    "### Main part - loop over many pressures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f72dda5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # flow MSE and conductivity Hamming a.f.o input pressure\n",
    "\n",
    "# # Initiate MSE and Hamming matrices - MSE and Hamming for every iteration step (cols) a.f.o input p (rows)\n",
    "# MSE_arr = np.zeros([Variabs.iterations, len(input_p)])\n",
    "# Hamming_arr = np.zeros([Variabs.iterations, len(input_p)])\n",
    "# power_dissip_arr = np.zeros([Variabs.iterations, len(input_p)])\n",
    "# convergence_time_vec = np.zeros([len(input_p), ])\n",
    "# # theta_vec = np.zeros([len(input_p), ])\n",
    "# shear_vec = np.zeros([len(input_p), ])  # \n",
    "# u_allostery_arr = np.zeros([2, 2, len(input_p)])  # \n",
    "\n",
    "# # Identify edges at connections of cells and at boundaries for ease of use\n",
    "# Strctr.Boundaries_and_connections(Variabs)\n",
    "\n",
    "# origin = np.array([[0, 0],[0, 0]]) # origin point\n",
    "\n",
    "# print('started main loop')\n",
    "\n",
    "# for i, p in enumerate(input_p):\n",
    "    \n",
    "#     # save variables into class\n",
    "#     Variabs.assign_input_p(p)\n",
    "    \n",
    "#     # Set up constraints for whole loop\n",
    "#     Strctr.Setup_constraints(Variabs)\n",
    "    \n",
    "#     # Initiate K matrix again, not mandatory, better not doing it actually\n",
    "#     State.initiateK(Variabs, Strctr, noise='no')\n",
    "    \n",
    "#     # Loop - Pose constraints, build constraints matrix, solve flow and update conductivities until convergence,\n",
    "#     #        change constraints and repeat\n",
    "#     State.flow_iterate(Variabs, Strctr, NET, 'w marbles', plot='no', savefig='no')\n",
    "    \n",
    "#     MSE_arr[:, i] = State.MSE\n",
    "#     Hamming_arr[:, i] = State.Hamming\n",
    "#     power_dissip_arr[:, i] = State.power_dissip\n",
    "#     convergence_time_vec[i] = State.convergence_time\n",
    "    \n",
    "#     State.flow_iterate(Variabs, Strctr, NET, 'allostery test', 'yes')\n",
    "#     print(State.u_final)\n",
    "    \n",
    "# #     Variabs.iterations = 1\n",
    "# #     State.flow_iterate(Variabs, Strctr, NET, 'w marbles', 'yes')\n",
    "# #     State.flow_iterate(Variabs, Strctr, NET, 'allostery test', 'yes')\n",
    "# #     print(State.u_final)\n",
    "    \n",
    "# #     Variabs.iterations = 2\n",
    "# #     State.flow_iterate(Variabs, Strctr, NET, 'w marbles', 'yes')\n",
    "# #     State.flow_iterate(Variabs, Strctr, NET, 'allostery test', 'yes')\n",
    "# #     print(State.u_final)\n",
    "    \n",
    "# #     Variabs.iterations = 3\n",
    "# #     State.flow_iterate(Variabs, Strctr, NET, 'w marbles', 'no')\n",
    "# #     State.flow_iterate(Variabs, Strctr, NET, 'allostery test', 'last')\n",
    "# #     print(State.u_final)\n",
    "    \n",
    "# #     Variabs.iterations = iterations\n",
    "    \n",
    "#     u_allostery_arr[:,:, i] = State.u_final\n",
    "#     shear_vec[i] = Statistics.shear_type(State.u_final)\n",
    "#     print('shear is: ' + str(shear_vec[i]))\n",
    "    \n",
    "#     print(str((i+1)*100/len(input_p)) + '% done')\n",
    "\n",
    "# convergence_time_vec[np.isnan(convergence_time_vec)] = Variabs.iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd721f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# State.flow_iterate(Variabs, Strctr, NET, 'allostery test', 'yes', savefig='yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf292d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ## Figures\n",
    "\n",
    "# # prelims for figures\n",
    "# datenow = datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "# print(datenow)\n",
    "\n",
    "# # fig 1 - MSE, Hamming and Power dissip. afo p\n",
    "\n",
    "# fig1, axes1 = plt.subplots(nrows=3)\n",
    "# # axes.set_color_cycle(['332288', '88CCEE', '44AA99', '117733', '999933', 'DDCC77', 'CC6677', '882255', 'AA4499'])\n",
    "# # cmap = plt.get_cmap('cool')\n",
    "# cmap = sns.cubehelix_palette(as_cmap=True)\n",
    "# colors = [cmap(i) for i in np.linspace(0, 1, len(MSE_arr[0,:]))]\n",
    "# legend_every = 10\n",
    "\n",
    "# for i, color in enumerate(colors, start=0):\n",
    "#     if i % legend_every == 0:\n",
    "#         axes1[0].plot(range(len(MSE_arr[:,0])), MSE_arr[:,i], color=color, label='p='+str(input_p[i]))\n",
    "#     else:\n",
    "#         axes1[0].plot(range(len(MSE_arr[:,0])), MSE_arr[:,i], color=color)\n",
    "#     axes1[1].plot(range(len(MSE_arr[:,0])), Hamming_arr[:,i], color=color)\n",
    "#     axes1[2].plot(range(len(MSE_arr[:,0])), power_dissip_arr[:,i]/input_p[i], color=color)\n",
    "# axes1[0].legend()\n",
    "# # plt.show()\n",
    "# axes1[2].set_xlabel('iteration #')\n",
    "# axes1[0].set_ylabel('flow MSE')\n",
    "# axes1[1].set_ylabel('Hamming dist.')\n",
    "# axes1[2].set_ylabel('power')\n",
    "\n",
    "# ## Save last figure as PNG with proper time\n",
    "# plt.savefig(comp_path + 'distance_and_P_afo_p_' + \"_grid=\" + str(NGrid) + \"_\" + str(datenow) + '.png')\n",
    "\n",
    "# # fig 2 - # cycles until convergence and tau p\n",
    "\n",
    "# fig2, axes2 = plt.subplots(nrows=2, figsize=(10,6))\n",
    "# axes2[0].semilogx(input_p, convergence_time_vec, '.', ms=20, mfc='white', label='# cycles until convergence')\n",
    "# axes2[0].set_ylabel('# cycles')\n",
    "# # axes2[1].plot(input_p, theta_vec, '.', ms=20, mfc='white', label='$\\\\theta$')\n",
    "# # axes2[1].set_xlabel('input $p$')\n",
    "# # axes2[1].set_ylabel('$\\\\theta$')\n",
    "# axes2[1].semilogx(input_p, shear_vec, '.', ms=20, mfc='white', label='$\\\\tau$')\n",
    "# axes2[1].semilogx(input_p, np.zeros([len(input_p),]))\n",
    "# axes2[1].set_xlabel('input $p$')\n",
    "# axes2[1].set_ylabel('$\\\\tau$')\n",
    "\n",
    "# ## Save last figure as PNG with proper time\n",
    "# plt.savefig(comp_path + 'numCycles_and_tau_afo_p_' + \"_grid=\" + str(NGrid) + \"_\" + str(datenow) + '.png')\n",
    "\n",
    "# # fig2 = plt.figure(figsize = (10,4))\n",
    "# # plt.plot(input_p, convergence_time_vec, '.', ms=20, mfc='white', label='# cycles until convergence')\n",
    "# # plt.xlabel('input $p$')\n",
    "# # plt.ylabel('# cycles')\n",
    "# # # plt.legend(loc='upper right')\n",
    "# # plt.legend()\n",
    "\n",
    "# # plt.show()\n",
    "\n",
    "# # fig3 = plt.figure(figsize = (10,4))\n",
    "# # plt.plot(input_p, theta_vec, '.', ms=20, mfc='white', label='$\\\\theta$')\n",
    "# # plt.xlabel('input $p$')\n",
    "# # plt.ylabel('$\\\\theta$')\n",
    "# # # plt.legend(loc='upper right')\n",
    "# # plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save inportant data as CSV\n",
    "\n",
    "# # import pandas as pd \n",
    "\n",
    "# datenow = datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "# print(datenow)\n",
    "\n",
    "# # df1 = pd.DataFrame(u_allostery_arr)\n",
    "# # print('C:\\\\Users\\\\SMR_Admin\\\\OneDrive - huji.ac.il\\\\PhD\\\\Network Simulation repo\\\\Network\\\\u_allostery' + str(datenow) + '.csv')\n",
    "# # df1.to_csv(\"C:\\\\Users\\\\SMR_Admin\\\\OneDrive - huji.ac.il\\\\PhD\\\\Network Simulation repo\\\\Network\\\\u_allostery\" + str(datenow) + \".csv\")\n",
    "# df2 = pd.DataFrame(np.array([K_min, convergence_time_vec, shear_vec]))\n",
    "# df2.to_csv(comp_path + str(datenow) + \"_grid=\" + str(NGrid) + \"_shear_vec.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
